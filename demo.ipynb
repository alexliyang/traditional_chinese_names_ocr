{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chinese Name OCR based on CRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fiona/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers.convolutional import Conv2D,MaxPooling2D,ZeroPadding2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.core import Reshape,Masking,Lambda,Permute\n",
    "from keras.layers import Input,Dense,Flatten\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers.recurrent import GRU,LSTM\n",
    "from keras.layers.wrappers import Bidirectional\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras.preprocessing import image\n",
    "from keras.optimizers import Adam,SGD,Adadelta\n",
    "from keras import losses\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.callbacks import EarlyStopping,ModelCheckpoint,TensorBoard\n",
    "from keras.utils import plot_model\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import numpy as np \n",
    "import os\n",
    "from PIL import Image,ImageDraw,ImageFont \n",
    "import json\n",
    "import threading\n",
    "import pandas as pd\n",
    "from opencc import OpenCC \n",
    "\n",
    "import tensorflow as tf  \n",
    "import keras.backend.tensorflow_backend as K  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_corpus = pd.read_csv(\"./input/chinese_names_big5.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_corpus.columns=['name_sim_chi','len','name_tra_chi']\n",
    "name_corpus.to_csv(\"./input/chinese_names_big5.csv\",index=False)\n",
    "name_corpus.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In total, there are 1,203,132 Chinese names with maximum name length of 3. There are 2,361 distinct characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total name is 1203132\n",
      "possible name length is \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2, 3])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"total name is {}\".format(len(name_corpus)))\n",
    "\n",
    "print(\"possible name length is \")\n",
    "name_corpus['len'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting to see the distribution of Chinese surname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>char</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>王</th>\n",
       "      <td>55563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>李</th>\n",
       "      <td>53945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>張</th>\n",
       "      <td>51714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>陳</th>\n",
       "      <td>45452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>劉</th>\n",
       "      <td>43730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>文</th>\n",
       "      <td>36625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>林</th>\n",
       "      <td>34617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>華</th>\n",
       "      <td>31981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>楊</th>\n",
       "      <td>30116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>明</th>\n",
       "      <td>30015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>黃</th>\n",
       "      <td>26648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>吳</th>\n",
       "      <td>25739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>金</th>\n",
       "      <td>24362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>周</th>\n",
       "      <td>22406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>曉</th>\n",
       "      <td>22315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>玉</th>\n",
       "      <td>21701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>趙</th>\n",
       "      <td>21144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>國</th>\n",
       "      <td>20522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>海</th>\n",
       "      <td>20218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>徐</th>\n",
       "      <td>19549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>偉</th>\n",
       "      <td>19043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>志</th>\n",
       "      <td>18657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>平</th>\n",
       "      <td>18628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>紅</th>\n",
       "      <td>18490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>朱</th>\n",
       "      <td>17688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>麗</th>\n",
       "      <td>17582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>春</th>\n",
       "      <td>17579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>建</th>\n",
       "      <td>17470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>孫</th>\n",
       "      <td>17447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>雲</th>\n",
       "      <td>16767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>托</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>廕</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>紮</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>緻</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>涌</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>叶</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>万</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>栗</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>我</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>噹</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>彔</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>啊</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>口</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>蔘</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>党</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>下</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>絃</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>枱</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>麴</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>苹</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>彆</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>糰</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>捲</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>蹟</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>蕓</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>适</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>愿</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>几</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>鉅</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>鑒</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2361 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      count\n",
       "char       \n",
       "王     55563\n",
       "李     53945\n",
       "張     51714\n",
       "陳     45452\n",
       "劉     43730\n",
       "文     36625\n",
       "林     34617\n",
       "華     31981\n",
       "楊     30116\n",
       "明     30015\n",
       "黃     26648\n",
       "吳     25739\n",
       "金     24362\n",
       "周     22406\n",
       "曉     22315\n",
       "玉     21701\n",
       "趙     21144\n",
       "國     20522\n",
       "海     20218\n",
       "徐     19549\n",
       "偉     19043\n",
       "志     18657\n",
       "平     18628\n",
       "紅     18490\n",
       "朱     17688\n",
       "麗     17582\n",
       "春     17579\n",
       "建     17470\n",
       "孫     17447\n",
       "雲     16767\n",
       "...     ...\n",
       "托         3\n",
       "廕         3\n",
       "紮         3\n",
       "緻         3\n",
       "涌         3\n",
       "叶         3\n",
       "万         3\n",
       "栗         2\n",
       "我         2\n",
       "噹         2\n",
       "彔         2\n",
       "啊         2\n",
       "口         2\n",
       "蔘         2\n",
       "党         2\n",
       "下         2\n",
       "絃         2\n",
       "枱         2\n",
       "麴         2\n",
       "苹         2\n",
       "彆         1\n",
       "糰         1\n",
       "捲         1\n",
       "蹟         1\n",
       "蕓         1\n",
       "适         1\n",
       "愿         1\n",
       "几         1\n",
       "鉅         1\n",
       "鑒         1\n",
       "\n",
       "[2361 rows x 1 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_set=list(set(name_corpus['name_tra_chi']))\n",
    "\n",
    "char_list=[]\n",
    "\n",
    "for name in name_set:\n",
    "    char_list.extend(list(name))\n",
    "    \n",
    "char_to_id = {j:i for i,j in enumerate(char_list)}\n",
    "id_to_char = {i:j for i,j in enumerate(char_list)}\n",
    "\n",
    "char_df = pd.DataFrame(data=char_list)\n",
    "char_df.columns=['char']\n",
    "char_df['count']=1\n",
    "char_stat = char_df.groupby('char').sum().sort_values(by='count',ascending=False)\n",
    "char_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## initialize gloabl variables\n",
    "\n",
    "maxlabellength = 3\n",
    "img_h = 32\n",
    "img_w = 248\n",
    "nclass = len(char_stat)\n",
    "rnnunit=256\n",
    "batch_size =64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy MingLiu font from Windows/fonts to Ubuntu /usr/share/fonts and update system font cache\n",
    "\n",
    "- sudo mkfontscale (if package missing need to do sudo apt-get installttf-mscorefonts-installer)\n",
    "- sudo mkfontdir (if package missing need to do sudo apt-get install fontconfig)\n",
    "- sudo fc-cache -fv( refresh system font cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "font=ImageFont.truetype('/usr/share/fonts/truetype/windows/mingliu0.ttf',24) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate training image for Chinese name in MingLiu font\n",
    " - training image by random generation\n",
    " - validation image by random generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_image_sample(n=100,image_path='./train/train_',label_path = \"./train/train_label.csv\"):\n",
    "    sample_name=name_corpus.sample(n)\n",
    "    for index, row in sample_name.iterrows():\n",
    "\n",
    "        img = img = Image.new('L',(img_w,img_h),(255))\n",
    "        draw = ImageDraw.Draw(img)  \n",
    "        name = row['name_tra_chi']\n",
    "        label = \"\"\n",
    "        for chr in name:\n",
    "            label = label + chr +\" \"\n",
    "        draw.text((0,5),label.strip() ,fill=(0),font=font)  \n",
    "        img.save(image_path+str(index)+'.png')\n",
    "\n",
    "    sample_name.reset_index().to_csv(label_path,index=False)  \n",
    "    return sample_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image = generate_image_sample(1000,'./train/train_','train/train_label.csv')\n",
    "y_train = train_image['name_tra_chi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_image = generate_image_sample(100,'./validate/valid_','validate/valid_label.csv')\n",
    "y_valid = validate_image['name_tra_chi']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "design of the deep learning model: VGG + Bidirectional LSTM + CTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "the_input (InputLayer)       (None, 32, 248, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 32, 248, 64)       640       \n",
      "_________________________________________________________________\n",
      "pool1 (MaxPooling2D)         (None, 16, 124, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 16, 124, 128)      73856     \n",
      "_________________________________________________________________\n",
      "pool2 (MaxPooling2D)         (None, 8, 62, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv3 (Conv2D)               (None, 8, 62, 256)        295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 8, 62, 256)        1024      \n",
      "_________________________________________________________________\n",
      "conv4 (Conv2D)               (None, 8, 62, 256)        590080    \n",
      "_________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPaddin (None, 8, 64, 256)        0         \n",
      "_________________________________________________________________\n",
      "pool3 (MaxPooling2D)         (None, 4, 63, 256)        0         \n",
      "_________________________________________________________________\n",
      "conv5 (Conv2D)               (None, 4, 63, 512)        1180160   \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 4, 63, 512)        2048      \n",
      "_________________________________________________________________\n",
      "conv6 (Conv2D)               (None, 4, 63, 512)        2359808   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPaddin (None, 4, 65, 512)        0         \n",
      "_________________________________________________________________\n",
      "pool4 (MaxPooling2D)         (None, 2, 64, 512)        0         \n",
      "_________________________________________________________________\n",
      "conv7 (Conv2D)               (None, 1, 63, 512)        1049088   \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 1, 63, 512)        2048      \n",
      "_________________________________________________________________\n",
      "permute (Permute)            (None, 63, 1, 512)        0         \n",
      "_________________________________________________________________\n",
      "timedistrib (TimeDistributed (None, 63, 512)           0         \n",
      "_________________________________________________________________\n",
      "blstm1 (Bidirectional)       (None, 63, 512)           1181184   \n",
      "_________________________________________________________________\n",
      "blstm1_out (Dense)           (None, 63, 256)           131328    \n",
      "_________________________________________________________________\n",
      "blstm2 (Bidirectional)       (None, 63, 512)           787968    \n",
      "_________________________________________________________________\n",
      "blstm2_out (Dense)           (None, 63, 2361)          1211193   \n",
      "=================================================================\n",
      "Total params: 8,865,593\n",
      "Trainable params: 8,863,033\n",
      "Non-trainable params: 2,560\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input = Input(shape=(img_h,None,1),name='the_input')\n",
    "\n",
    "m = Conv2D(64,kernel_size=(3,3),activation='relu',padding='same',name='conv1')(input)\n",
    "m = MaxPooling2D(pool_size=(2,2),strides=(2,2),name='pool1')(m)\n",
    "m = Conv2D(128,kernel_size=(3,3),activation='relu',padding='same',name='conv2')(m)\n",
    "m = MaxPooling2D(pool_size=(2,2),strides=(2,2),name='pool2')(m)\n",
    "m = Conv2D(256,kernel_size=(3,3),activation='relu',padding='same',name='conv3')(m)\n",
    "m = BatchNormalization(axis=3)(m)\n",
    "m = Conv2D(256,kernel_size=(3,3),activation='relu',padding='same',name='conv4')(m)\n",
    "\n",
    "m = ZeroPadding2D(padding=(0,1))(m)\n",
    "m = MaxPooling2D(pool_size=(2,2),strides=(2,1),padding='valid',name='pool3')(m)\n",
    "\n",
    "m = Conv2D(512,kernel_size=(3,3),activation='relu',padding='same',name='conv5')(m)\n",
    "m = BatchNormalization(axis=3)(m)\n",
    "m = Conv2D(512,kernel_size=(3,3),activation='relu',padding='same',name='conv6')(m)\n",
    "\n",
    "m = ZeroPadding2D(padding=(0,1))(m)\n",
    "m = MaxPooling2D(pool_size=(2,2),strides=(2,1),padding='valid',name='pool4')(m)\n",
    "m = Conv2D(512,kernel_size=(2,2),activation='relu',padding='valid',name='conv7')(m)\n",
    "\n",
    "m = BatchNormalization(axis=3)(m)\n",
    "m = Permute((2,1,3),name='permute')(m)\n",
    "m = TimeDistributed(Flatten(),name='timedistrib')(m)\n",
    "\n",
    "m = Bidirectional(GRU(rnnunit,return_sequences=True,implementation=2),name='blstm1')(m)\n",
    "#m = Bidirectional(LSTM(rnnunit,return_sequences=True),name='blstm1')(m)\n",
    "m = Dense(rnnunit,name='blstm1_out',activation='linear',)(m)\n",
    "#m = Bidirectional(LSTM(rnnunit,return_sequences=True),name='blstm2')(m)\n",
    "m = Bidirectional(GRU(rnnunit,return_sequences=True,implementation=2),name='blstm2')(m)\n",
    "y_pred = Dense(nclass,name='blstm2_out',activation='softmax')(m)\n",
    "\n",
    "basemodel = Model(inputs=input,outputs=y_pred)\n",
    "basemodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ctc_lambda_func(args):\n",
    "    y_pred,labels,input_length,label_length = args\n",
    "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = Input(name='the_labels',shape=[maxlabellength],dtype='float32')\n",
    "input_length = Input(name='input_length', shape=[1], dtype='int64')\n",
    "label_length = Input(name='label_length', shape=[1], dtype='int64')\n",
    "\n",
    "loss_out = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([y_pred, labels, input_length, label_length]) \n",
    "\n",
    "model = Model(inputs=[input, labels, input_length, label_length], outputs=loss_out)\n",
    "\n",
    "adadelta = Adadelta()\n",
    "model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=adadelta,metrics=['accuracy'])\n",
    "checkpoint = ModelCheckpoint(r'weights-{epoch:02d}.hdf5',save_weights_only=True)\n",
    "earlystop = EarlyStopping(patience=10)\n",
    "tensorboard = TensorBoard(r'crnn/logs',write_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_name(index):\n",
    "    \n",
    "    return \"./train/train_\"+str(index)+\".png\"\n",
    "\n",
    "def generate_image_from_file(path,batch_size=64,maxlabellength=3):\n",
    "    \n",
    "   \n",
    "    images = pd.read_csv(path)\n",
    "    images['file_name']=images['index'].apply(image_name)\n",
    "    \n",
    "    #print(images.head())\n",
    "    \n",
    "    x = np.zeros((batch_size, img_h, img_w, 1), dtype=np.float)\n",
    "    labels = np.ones([batch_size,maxlabellength])\n",
    "    input_length = np.zeros([batch_size,1])\n",
    "    label_length = np.zeros([batch_size,1])\n",
    "    \n",
    "    samples = images.sample(batch_size).reset_index()\n",
    "\n",
    "   \n",
    "    while 1:\n",
    "       \n",
    "        for i,row in samples.iterrows():\n",
    "            img1 = Image.open(row['file_name'])\n",
    "            img = np.array(img1,'f')/255.0-0.5\n",
    "           \n",
    "            x[i] = np.expand_dims(img,axis=2)\n",
    "            name = row['name_tra_chi']\n",
    "            label_length[i] = len(name)        \n",
    "            input_length[i] = img_w//4+1\n",
    "            labels[i,:len(name)] = [char_to_id[i] for i in name]\n",
    "        \n",
    "\n",
    "        inputs = {'the_input': x,\n",
    "                 'the_labels': labels,\n",
    "                 'input_length': input_length,\n",
    "                 'label_length': label_length,\n",
    "                }\n",
    "        outputs = {'ctc': np.zeros([batch_size])} \n",
    "        yield (inputs,outputs)            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "  63/1000 [>.............................] - ETA: 18265s - loss: 29.0915 - acc: 0.7138"
     ]
    }
   ],
   "source": [
    "model.fit_generator(generate_image_from_file('./train/train_label.csv',batch_size=batch_size),\\\n",
    "                    steps_per_epoch=len(train_image), \\\n",
    "                    validation_data =generate_image_from_file('./validate/valid_label.csv',batch_size=batch_size) ,\\\n",
    "                    validation_steps = len(validate_image),\\\n",
    "                    epochs=10,\\\n",
    "                    verbose=1,\\\n",
    "                    callbacks =[earlystop,checkpoint,tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('crnn_model_weights.h5')\n",
    "model.to_json('model_structure.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.predict(x, batch_size=None, verbose=0, steps=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
